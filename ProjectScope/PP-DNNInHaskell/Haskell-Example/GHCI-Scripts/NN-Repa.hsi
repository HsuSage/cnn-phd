import qualified Data.Array.Repa                   as RP
import qualified Data.Array.Repa.Algorithms.Matrix as RP

inputNodes = 784
outputNodes = 10
hiddenNodes = 5
-- inputNodes = 4
-- outputNodes = 3
-- hiddenNodes = 2
lrate = 0.01
epochs = 1

nnBase = NNBase inputNodes hiddenNodes outputNodes lrate
nn <- createNNR nnBase

trainedNN <- readCVSR "../MNIST-Data/MNIST-Test-10.csv" epochs nn
testedNN <- queryCVSR "../MNIST-Data/MNIST-Test-10.csv" trainedNN

-- listWIH = fromListUnboxed (ix2 hiddenNodes inputNodes) [0..(inputNodes * hiddenNodes - 1)] :: NNLayerR
-- listWHO = fromListUnboxed (ix2 outputNodes hiddenNodes) [0..(hiddenNodes * outputNodes - 1)] :: NNLayerR

-- nn = NeuralNetworkR lrate listWIH listWHO

linesCSV <- readCVSFile "../MNIST-Data/MNIST-Test-10.csv"
layers = map cleanLayerR linesCSV
inputs = snd $ layers !! 0
training = desiredOutputR $ fst (layers !! 0)

-- inputs = fromListUnboxed (ix1 inputNodes) [0..(inputNodes - 1)] :: NLayerR
-- inputsM = fromListUnboxed (ix2 hiddenNodes inputNodes) [0..(hiddenNodes * inputNodes - 1)] :: NNLayerR
-- training = fromListUnboxed (ix1 outputNodes) [0..(outputNodes - 1)] :: NLayerR

(NeuralNetworkR lRateNN wihNN whoNN) = nn

--ll = traverse2 wihNN inputs (\sh _ -> sh) (\f g sh@(Z :. x :. y) -> f sh )
--ll = traverse2 wihNN inputs (\sh _ -> sh) (\f g sh@(Z :. x :. y) -> g (Z :. ( x)) )
--ll = traverse2 wihNN inputs (\sh _ -> sh) (\f g sh@(Z :. x :. y) -> g (Z :. (y)) )
--ll = traverse2 wihNN inputs (\(Z :. x :. y) _ -> (Z :. y :. x)) (\f g sh@(Z :. x :. y) -> (g (Z :. y)) )
--ll = traverse2 wihNN inputs (\(Z :. x :. y) _ -> (Z :. y :. x)) (\f g sh@(Z :. x :. y) -> (f ((Z :. y :. x))) )
--ll = traverse2 wihNN inputs (\sh _ -> sh) (\f g sh@(Z :. x :. y) -> (f ((Z :. y :. x))) * (g (Z :. x)) )
-- ll = traverse2 wihNN inputs (\sh _ -> sh) (\f g sh@(Z :. x :. y) -> (f sh) * (g (Z :. x)) )
-- pre <- computeP . transpose $ ll:: IO NNLayerR
-- (\sh1@(Z :sx _) _ -> Z :. )

hiddenInputs <-  matVecDense wihNN inputs
-- extent hiddenInputs
hiddenOutputs <- activationFuncR hiddenInputs
-- extent hiddenOutputs
whoNNT <- computeP $ transpose whoNN :: IO NNLayerR
-- extent whoNNT
finalInputs <- matVecDense whoNN hiddenOutputs
-- extent finalInputs
finalOutputs <- activationFuncR finalInputs
-- extent finalOutputs
outputErrors <- computeP $ training -^ finalOutputs :: IO NLayerR
-- extent outputErrors
hiddenErrors <- matVecDense whoNNT outputErrors
-- extent hiddenErrors
preWHO <- kerMap outputErrors finalOutputs hiddenOutputs
-- extent preWHO
preWIH <- kerMap hiddenErrors hiddenOutputs inputs
extent preWIH
whoDelta <- computeP . transpose  $ map (lRateNN *) preWHO :: IO NNLayerR
extent whoDelta

wihDelta <- computeP . transpose $ map (lRateNN *) preWIH :: IO NNLayerR
extent wihDelta
wihFin <- computeP $ wihNN +^ wihDelta :: IO NNLayerR
extent wihFin
whoFin <- computeP $ whoNN +^ whoDelta :: IO NNLayerR
extent whoFin


nnR <- analyzeLinesR epochs nn linesCSV
nnR' <- analyzeLinesR' epochs nn linesCSV