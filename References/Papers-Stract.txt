Use Haskell-Clash to develop a CNN for HFT

------> Fin

Adjoints and automatic (algorithmic) differentiation in computational finance
- Use AD to reduce computation time, increase accuracy 
- Create an "adjoint" for reverse computations
- Applied to Monte Carlo Simulations for the Greeks

------> CNN

Applications of Convolutional Neural Networks
- Describe different known applications of CNN
- Computer vision and Natural language processing as their main applications
- Improvements over LSTM RNN, SVN

Recent Advances in Convolutional Neural Networks
- The CNN tree of components, optimizations and applications
- Link to other publications about types of CNN
- General applications in which CNN have been used
- General explanation of how CNN works

Wavelet pooling for convolutional neural networks
- Use wavelet pooling to reduce feature dimensions.
- Uses MatConvNet
- Executed on Intel i7-6800K, 64GB
- MIST, CIFAR, SHVN and KDEF as its applications

Automatic differentiation in machine learning- a survey
- Use automatic diff for gradient decent learning techniques
- Explains what AD is not: numerical diff, symbolic diff.
- Explains how to perform AD and its modes
- How AD and back propagation relate

Deep Convolutional Inverse Graphics Network
- Propose a new architecture for NN using (de)convolutions
- Outputs resistant to rotations, translations or light changes
- Training using "Stochastic Gradient Variational Bayes"
- Image input -> new images with different pose or light
- Applications as well for 3D rendering

Show, Attend and Tell: Neural Image Caption Generation with Visual Attention
- Use convolution and LSTM to extract text information from images
- Flickr8k, Flickr30k and MS COCO datasets with BLEU and METEOR metrics
- MS COCO trained for 3 days using a Titan GPU
- It explains two stochastic attentions: soft and hard

Convolutional Neural Network on Neural Compute Stick for Voxelized Point-clouds Classification
- Used CNN for object recognition on volumetric data
- Proposed a 3D voxelized cloud points generation
- Voxel tree representation "VOLA" (Volumetric accelerator)
- Used Movidious Neural Compute USB stick to accelerate the training (~1.2W)

Eyeriss- An Energy-Efficient Reconfigurable Accelerator for Deep Convolutional Neural Networks
- Eyeriss is a chip designed for CNN operations
- Caffe runs on Jetson TK1 <-> PCI-Express of Xilinx VC707 <-> Eyeriss
- Eyeriss is a 65nm, 200MHz, 168 PE, 16bit fixed point and adaptively-fixed CNN shapes
- Native support for Caffe
- Used AlexNet (227x227) and VGG-16 (224x224)

Designing Energy-Efficient Convolutional Neural Networks using Energy-Aware Pruning
- Energy-aware pruning algorithm for CNNs 
- Uses the energy consumption to guide the pruning process
- Minimizes error in the output feature maps instead of weights filter
- Reduce energy consumption: AlexNet (3.7x) and GoogLeNet (1.6x)
- Accuracy after pruning, less than 1% loss

------> CNN-Fin

Intraday prediction of Borsa Istanbul using convolutional neural networks and feature correlations
- Use of CNN to predict stock market price movement using random and naïve   series
- CNN better than Macro Average F-Measure for random and correlated features
- Istanbul stock exchange

Forecasting Stock Prices from the Limit Order Book using Convolutional Neural Networks 
- CNN better than RNN, RBM (Restricted Boltzmann Machine), SVM (Support Vector Machines)
- Taiwan stock exchange

Financial Time-series Data Analysis using Deep Convolutional Neural Networks 
- Transform data into an image
- Executed on a CPU using Matlab

Deep learning for event-driven stock prediction
- Use news as a feature in the CNN
- Comparison of different CNN for market prediction
- NN vs CNN
- Profitability of the CNN against other publications
- S&P stocks

Convolutional Neural Networks Applied to High-Frequency Market Microstructure Forecasting 
- Confirmation of CNN works "reasonably well" on forecasting price trend
- Explains the structure of their CNN for order book and event flow

Multi-Scale Convolutional Neural Networks for Time Series Classification
- Use Multi-Scale CNN for time series classification
- MCNN unifies classification, feature extraction and back propagation
- Comprehensive benchmarking against other TSC algorithms

Conditional Time Series Forecasting with Convolutional Neural Networks
- Use wave CNN to make TSF
- S&P,  Forex and CBOE interest rate as base data
- Comparison against Naïve, LSTM and VAR

Artificial Neural Networks architectures for stock price prediction comparisons and applications
- Implementation of MLP, CNN, LSTM
- Comparison of their performance
- CNN are better than other architectures
- An novel Wavelet-CNN was implemented.

Reading the Tea Leaves- A Neural Network Perspective on Technical Trading
- Use technical analysis for price prediction
- CNN, RNN and many other DNN models tested
- It concludes 'there is no evidence of predictive prowess'

Deep learning for stock market prediction from financial news articles
- Use RCNN compared against other type of CNN
- Use two sources: news and technical indicators
- Prefer sentence embedding rather than word embedding

------> NN-Fin

A Deep Neural-Network Based Stock Trading System Based on Evolutionary Optimized Technical Analysis Parameters 
- Use of NN un a trading system for 30 stocks of the Dow
- Next steps are going to make a CNN 
- Use SMA and RSI 

Adaptive Neuro Fuzzy Inference Systems for High Frequency Financial Trading and Forecasting
- Another Machine learning technique: Adaptive Neuro-Fuzzy Inference System
- Use Sharpe and Sortino ratio
- Comparison against buy and hold
- FOREX for EUR/USD

Using Recurrent Neural Networks To Forecasting of Forex
- Use NN for time series forecasting
- CHF, GBP, Euro and JPN
- Use this as a relation with Bitcoin exchange

Deep learning networks for stock market analysis and prediction - Methodology, data representations, and case studies
- Comprehensive review of current publications
- Use data from the Korean Stock market
- Uses a simple DNN with 3 layers

Adaptive Hybrid Higher Order Neural Networks for Prediction of Stock Market Behavior
- Use Pi-Sigma HONN to make market predictions
- Used for Index and stocks in the USA market
- Used a genetic algorithm and compared that with a gradient decent
- Improved case of GA over GD

Two-Step Disentanglement for Financial Data
- Compare their proposed method with CAPM, Black-Sholes and GAN
- Use their method with MNIST, Sprites NORB, YaleB databases
- Used Nasdaq, NYSE, and AMEX data from 1976-2009
- Beta, rho and mean as benchmarks.
- "our algorithm encodes it as two separate parts, one that keeps the information regarding the labels and the other that is agnostic to the labels"

New Neural Networks Based on Taylor Series and their Research
- Propose NNs based on: Taylor series, a radial basis neuron and Fourier component neuron
- Mentions financial datasets, but no consistent results are provided
- It also proposes the combination of different types: Fourier, gauss or taylor components

An Efficient Neural Network Model with Taylor Series-Based Data Pre-processing for Stock Price Forecast
- Use fundamental and technical EPS and MACD as input data
- Hand picked stock data of some Taiwan public companies
- Their model mentions a remarkable return and high accuracy strategies
- It applies the form of Taylor series to preprocess data

Functional data learning by Hilbert feedforward neural networks
- The "Hilbert parallel overrelaxation backpropagation (HPORBP) algorithm" is proposed
- Mentioned that HPORBP has better accuracy than the Hilbert backpropagation algorithm
- It has embedded considerations for parallel execution

------> FPGA

Recent Trends in FPGA Architectures and Applications
- Current state for platforms and tools of FPGAs
- Where FPGA are being used: radio astronomy, chip multiprocessor emulation,
particle physics and derivate pricing


Accelerating Large-Scale HPC Applications Using FPGAs
- Use FPGA to accelerate High performance computing
- Comparison with x86
- Modeling wave propagation and credit derivates as its applications

A Pythonic Approach for Rapid Hardware Prototyping and Instrumentation
- Use python as HDL language
- Runs on a Xilinx PynQ Platform
- Also allows simulation within the board

Floating-point bitwidth analysis via automatic differentiation
- Use AD to analyze the circuit and specify floating point precision
- Applied to D-FFT and Finite Impulse Response filter
- C++ implementation

Combined Spatial and Temporal Blocking for High-Performance Stencil Computation on FPGAs Using OpenCL
- Compare GPU vs FPGA for 2D/3D stencil computations
- Implemented on OpenCL
- Better performance despite lower memory bandwidth
- Simpler FPGA code rather than GPU implementations

------> FPGA-NN

ESE- Efficient Speech Recognition Engine with Sparse LSTM on FPGA
- Implement a LSTM on Xilinx XCKU060 
- 3x faster than GPU Pascal Titan
- 11.5x efficient GPU
- Used Sparse Matrix-vector Multiplication with 16bit wide elements (12quant + 4index)

Hardware-efficient on-line learning through pipelined truncated-error backpropagation in binary-state networks
- Trained with MNIST data
- Implemented on a Spartan 6 FPGA
- On-line learning technique for FF-NN based on pipelined backpropagation
- Removes the need for an explicit backward pass
- Used Binary State Networks instead of common spiked ones

Towards a Multi-array Architecture for Accelerating Large-scale Matrix Multiplication on FPGAs
- Novel implementation of Matrix multiplication
- Applied to CNN
- Computes floating point operations
- Dynamic creation of "PE" to compute matrix elements

Development and Implementation of Parameterized FPGA-Based General Purpose Neural Networks for Online Applications
- Show a "Generalized backpropagation multilayer perceptron" on FPGAs
- Tries to minimize cost, maximize accuracy, performance and parametrization
- Divide neurons into "Processing Elements"
- It considers online training of the NN

Artificial Neural Network Implementation on a single FPGA of a Pipelined On- Line Backpropagation
- Implements a systolic array for multilayer perceptron
- Used a Virtex XCV400
- Pipelined adaptation of the back-propagation algorithm
- Uses two degrees of parallelism: synapse-oriented and forward-backward parallelism

------> FPGA-Fin

Computing system and network architectures in high frequency trading financial applications
- Use Networked FPGAs to obtain sub-microsecond data transfer
- CUDA for HFT algorithm
- Comparison of different CUDA implementations
- x86 vs GPUs

A Hybrid Genetic-Programming Swarm-Optimisation Approach for Examining the Nature and Stability of High Frequency Trading Strategies
- Use genetic algorithms for HFT strategies
- FPGA performs the genetic calculations (15.62x over CPU)
- CPU - FPGA - CPU structure

A Low-Latency Library in FPGA Hardware for High-Frequency Trading (HFT)
- Sustain why low latency is important in HFT transactions
- Whole trading system in the FPGA
- Advantages and disadvantages of a whole system in a FPGA
- "Building and verifying new hardware is more time- consuming than writing new software due to the significantly lower abstraction level in the design flow"
- High throughput 6.1M FIX messages/sec
- FIX as protocol of communication

DSL programmable engine for high frequency trading acceleration
- FPGA vs x86 vs PowerPC
- FAST as protocol of communication
- Directly connected from network to FPGA
- Decreased latency, increased data rate
- DSL for programming via software

FPGA acceleration of quasi-Monte Carlo in finance
- Advantages of using  instead of x86
- Novel publication of quasi-Monte Carlo simulation

High-Performance Quasi-Monte Carlo Financial Simulation: FPGA vs. GPP vs. GPU
- Comparison of FPGA vs other computing architectures
- Financial derivates and QMC simulation
- Throughput and efficiency are compared
- Verilog for FPGA programming
- Speed Up of ~544X vs CPU; 50x vs GPU
- Consumption of 336x CPU, 16x GPU

Low latency book handling in FPGA for high frequency trading
- FPGA implementation of a order book
- Reduced lookup latency
- Large storage due to memory arrangements

Low-Latency FPGA Based Financial Data Feed Handler
- FPGA implementation for data feeds
- FPGA vs CPU
- Almost planar latency when feed rate is increased  on FPGA
- CPU varies linearly positive

Multiplierless Algorithm for Multivariate Gaussian Random Number Generation in FPGAs
- Comparison of FPGA vs CPU vs GPU
- Monte Carlo simulations
- 10x vs GPU, 100X vs CPU

Selection and implementation of high-performance platforms in finance
- The third report, talks about FPGA implementation of a Monte Carlo simulation
- It used Automatic Differentiation to improve on the system performance
- It gives an overall overview of the whole system design
- On the experiments, it shows an improvement of 200x over a Xeon CPU

------> CNN-FPGA

A General Neural Network Hardware Architecture on FPGA
- Description of a general NN running on a FPGA
- Base case for CNN, DNN, RNN
- Energy efficient and real time applications

A GPU-Outperforming FPGA Accelerator Architecture for Binary Convolutional Neural Networks
- Implementation of a binary CNN
- Comparison with GPU
- 75x more energy efficient
- 8.3x faster
- Applied to image classification

CirCNN - Accelerating and Compressing Deep Neural Networks Using Block-Circulant Weight Matrices
- Mentions ARM processors along with FPGA chips
- CirCNN implementation
- It is important to reduce CNN complexity to enhance scalability when the model size grows

F-CNN: An FPGA-based framework for training Convolutional Neural Networks
- F-CNN is FPGA-CNN
- Comparison vs CPU and GPU in efficiency and throughput
- Whole implementation, with special focus on training
- Applied for handwritten recognition
- Hybrid design: CPU controller, FPGA accelerator

Why TanH is a Hardware Friendly Activation Function for CNNs
- An alternative activation function for CNN
- Minimum number of circuits required to deploy a CNN
- Comparison of ReLU, Sigmoid and TanH

PipeCNN- An OpenCL-Based Open-Source FPGA Accelerator for Convolution Neural Networks
- Github code at: https://github.com/doonny/PipeCNN
- Full implementation of a CNN on a FPGA
- It uses OpenCL/C++ for code implementation
- It details improvements over other FPGA implementations (2015,2016)
- Implements AlexNet and VGG on a DE5-Net board (Stratix V GXA7)

Minitaur, an Event-Driven FPGA-Based Spiking Network Accelerator
- Used MNIST and 20 newsgroups classification data sets
- Development based on "Spiking" event-driven NN 
- Aims robotics as one of its applications
- Executed on a Xilinx Spartan 6 ZTEX board

FINN- A Framework for Fast, Scalable Binarized Neural Network Inference
- Used MNIST data for its tests
- Implemented on a FPGA Zynq UltraScale+ ZU19EG
- Used Binary NN: Binary input activations, binary synapse weights and binary output activations

Automated Systolic Array Architecture Synthesis for High Throughput CNN Inference on FPGAs
- Implements CNN on a FPGA using a systolic array architecture
- Used Intel OpenCL SDK
- A "Continuous Integration" scheme was used: from code to deployment
- AlexNet and VGG16 models were evaluated with 32bit floating points


------> Haskell

Modeling of dynamic reconfigurable systems with Haskell
- Mathematical description of Run Time Reconfigurable systems
- Use high order functions to generalize rules of abstraction

Roll your own test bed for embedded real-time protocols: a Haskell experience
- Use QuickCheck to generate signals and statistical reliability analysis
- Emulate environments
- Test the physical layer networking

Haskell Ready to Dazzle the Real World
- Desired attributes of Haskell to use as a development language
- Bayesian networks with the Dazzle software program
- GUI interaction between Dazzle and wxHaskell

Financial Software on GPUs- Between Haskell and Fortran
- Haskell vs Fortran
- Describe a generic algorithm for pricing (monte carlo)
- Outline the benefits of FP for functional parallelization

Functional Differentiation of Computer Programs
- Presents an implementation of "Computational Differentiation" (AD synonimn)
- Uses haskell to make that implementation
- Brief introduction to Differential Algebra and its operators
- Applications: Hermite, Lambert functions, WKB expansions, etc

The simple essence of automatic differentiation
- Simplified abstractions about AD
- Use category theory to explain AD with simple terms
- Special emphasis in Forward and Reverse AD for backpropagation
- Theoretical proofs that RAD is more efficient and pararellizable

Compiling To Categories
- Use categorical abstractions to express functions
- With CCC, it is possible to link to Graphs, Circuits or Graphics
- Use Haskell tools to bridge to different platforms
- First approach to declare AD

Beautiful Differentiation
- It explains the details about Automatic Differentiation
- It gives a high level detail of how AD is implemented in haskell
- It generalizes for vector spaces

------> Haskell-FPGA

Haskell as a higher order structural hardware description language
- Published at the same time as "ClasH - From Haskell To Hardware"
- Defend hardware description as a mathematical function application

A mathematical approach towards hardware design 
- Defend that a functional design can be used for logic circuit deployments
- Use clash but also mentions bluespec
- Sustain how basic functions translate to circuits

A fine-grained parallel dataflow-inspired architecture for streaming applications
- Thesis where Haskell and Clash is used
- Description of logic circuits
- Dataflow and coarse-grained reconfigurable arrays used to defend the thesis

A transformation-based approach to hardware design using higher-order functions
- Thesis where Haskell and Clash is used
- Application particule filtering

A two step hardware design method using CλaSH
- A procedure to develop HDL programs with Haskell
- Particle filtering application
- Publication from (previous) thesis 

Comparing CλaSH and VHDL by implementing a dataflow processor
- in some cases, Clash can synthesize better than VHDL code
- Simpler to use a high level language for circuit design
- Application: Dataflow processor
- Less lines of code in clash vs VHDL
- Lower power consumption

ClasH - From Haskell To Hardware
- Master thesis outlining Clash
- Mentions other languages for HDL
- One case study: reduction circuit

Co-simulation between Clash and traditional HDLs
- Use cases for clash when using fpga simulators
- Use verilog procedural interface for the simulation

Specification of apertif polyphase filter bank in Clash
- One formal application of Clash: an apertif polyphase filter bank
- Improvements on performance and clock frequency

System-level modeling of dynamic reconfigurable designs using functional programming abstractions
- Use clash to assign a FPGA section as reconfigurable
- Run embedded linux on the platform


------> DNN

Deep Learning in Neural Networks - An Overview
- A whole survey on how DL has developed until 2014
- Explain origins of DL before 1940
- Special topics in DL: SL, RL, UL.
- References to CNN and its improvements

Deep reinforcement learning - an overview
- "Book" like publication explaining from ground up DNN and RL
- Outline several applications: games, robotics, NLP, Computer Vision, etc
- Provide a plethora of related resources

Wasserstein Learning of Deep Generative Point Process Models
- Use NYSE to train a NN for High frequency transactions
- Several databases with realtime data: MIMIC, Meme, MAS
- Compares its performance against other MLE procedures (¿Maximum Likelihood Estimate?)
- Uses "Temporal point processes" as its main differentiator
- Key words: Wasserstein distance training of RNN point process models

-------> NN

Backwards Differentiation in AD and Neural Nets- Past Links and New Opportunities
- Explains Backwards calculation of derivates or "backpropagation"
- Relates it to Automatic Derivation
- Its application to NN

Pixel Recurrent Neural Networks
- Detail RNN with pixel by pixel spatial dimensions
- Use MNIST, CIFAR, and ImageNet as sources
- Description of a better Diagonal-BiLSTM network.

Auto-Encoding Variational Bayes
- Join a probabilistic model "Variational Bayes" as a gradient learning method
- Deep explanation of the mathematics behind their reasoning
- Uses monte carlo gradient estimator.
- MNIST and Frey Face datasets
- Auto-Encoding VB (AEVB), that learns an approximate inference model using the SGVB estimator

Generative Adversarial Imitation Learning
- New general framework for directly extracting a policy from data
- Describe "Inverse reinforcement learning"
- Uses math to sustain their approach
- This algorithm is evaluated against physics-based control tasks

VIME: Variational Information Maximizing Exploration
- Use "Variational bayes" for Reinforcement Learning
- Backup their statements with mathematical models
- VIME helps training real physical models like: MountainCar, CartPoleSwingup or SwimmerGather
- "VIME is a curiosity-driven exploration strategy for continuous control tasks"

DRAW: A Recurrent Neural Network For Image Generation
- Applied to MNIST, CIFAR, SVHN
- According to authors it is able to generate highly realistic natural images
- "Loss function is a variational upper bound on the log-likelihood of the data"
- Uses two stages: decoding <-> encoding for image generation
- Authors showcase their findings in a youtube video: https://www.youtube.com/watch?v=Zt-7MI9eKEo

Improving Variational Inference with Inverse Autoregressive Flow
- Applied to MNIST, CIFAR
- IAF is a new type of normalizing flow
- Faster sampling in CIFAR thanks to log-likelihood results
- Used variational autoencoders with bidirectional inference 

Equilibrated adaptive learning rates for non-convex
optimization
- An alternative to stochastic gradient decent
- Used MNIST and CURVES datasets
- Experiments ran on a GPU
- It compares its results at par with RMSProp

Generating Sequences With Recurrent Neural Networks
- Use LSTM to generate realistic sequences containing long range structure
- According to authors: "system is able to generate highly realistic cursive
handwriting"
- Can work predicting characters or words
- Used for Penn Treebank and Hutter Prize Wikipedia datasets for text
- IAM Online Handwriting Database for real value data

Recurrent Models of Visual Attention
- Scale image processing considering regions of training
- RNN with back-propagation
- Internal RNN determines which sections should be considered from the whole input
- "Trained end-to-end using a policy gradient method"

Inferring Algorithmic Patterns with Stack-Augmented Recurrent Nets
- Learn how to grow the complexity of a model in a structured way
- Slight improvement using lists or stacks with RNN
- "Complex algorithmic patterns can be more easily learned by composing simpler algorithms"

Reinforcement Learning Neural Turing Machines - Revised
- Outline how a RL-NTM can interact with an input, memory and output "tapes"
- Gradual increments of the problem complexity, as "Curriculum learning"
- Their gradient checking procedure helped to debug any reinforce algorithm
- Used for simple tasks: copy, reverse, duplicate
- Possible future work to implement on a FPGA

Neural Machine Translation by Jointly Learning to Align and Translate
- Extend the classic Encoder - Decoder with a (soft)search-RNN
- It makes translations between english and french
- WMT parallel corpora as a dataset
- It compares its results quantitative and qualitatively

End-To-End Memory Networks
- RNN with (large) external memory
- Train a NN with explicit memory and recurrent attention, 
- A NN with "intuition" of information from a text
- Compared to baseline NN like: LSTM, MemNN and MemNN-WSH (weakly supervised heuristic)

Neural Turing Machines
- Extent the Von Neumann architecture to NN which differentiable end-to-end
- It is able to infer simple algorithms: copy, sort, associative recall.
- NTM interacts with its environment using input - output channels
- NTM uses a controller to read/write from a local memory module

GPU-Accelerated Adjoint Algorithmic Differentiation
- Implementation improvement over naïve AD code
- Feasible for multithreaded environments, specially GPUs
- CPU vs GPU implementations 
- Use vectorization to reduce tape size

Automatic Differentiation of Algorithms for Machine Learning
- Explains AD from basic calculus knowledge
- Links AD with ML algorithms
- Explains Forward and Reverse mode

Delving Deep into Rectifiers- Surpassing Human-Level Performance on ImageNet Classification
- Introduction of the PReLU function
- "improves model fitting and little overfitting risk"
- Better recognition levels for ImageNet 2012 classification dataset
- PReLu function is also trained using backpropagation
- Mention of a multi-GPU deployment

Adam- a method for stochastic optimization
- Algorithm for first-order gradient-based optimization, estimates of lower-order moments
- Computationally efficient, little memory requirements, invariant to rescaling
- Applies to multiple ML algorithms: DNN, Logistic Regression, Bias-correction term
- Aimed for ML problems with large datasets and/or high-dimensional parameter spaces

NetAdapt- Platform-Aware Neural Network Adaptation for Mobile Applications
- Algorithm that improves inference on mobile devices with trained models
- It includes direct metrics (empirical measurements) into its adaptation
- It tries to reduce resource consumption while keeping the same accuracy
- Tested for mobile CPU and GPUs

Hardware for Machine Learning- Challenges and Opportunities
- Abstract survey of hardware architectures: CPU, GPU, FPGA, ASIC
- General memory access SIMD models: Weight, output, row stationary or no local reuse
- Oportunities: reduced precision, sparcity, compression

Efficient Processing of Deep Neural Networks- A Tutorial and Survey
- Tutorial on past, present and future of DNN from a research perspective
- DNN Applications: image/video, speech/language, medical, game play, robotics
- DNN numerical precision survey according to the bitwidth 
- DNN models: LeNet, AlexNet, Overfeat, VGG, GoogLeNet, ResNet
- Techniques used on accelerators for SIMD operations
- Metrics for Hardware: power/energy, latency/throughput, cost

Understanding the Limitations of Existing Energy-Efficient Design Approaches for Deep Neural Networks
- "While specialized DNN hardware (ASIC, FPGA) provide improved energy-efficiency compared to GPUs, they often come at the cost of flexibility in terms layer types (CONV or FC) and network shapes that it can support; specifically they rely on certain DNN properties to achieve it"
- "On the other hand, innovative techniques have been used for efficient DNN algorithm design, adding diversification, which in turns, hardware needs to be flexible enough
to be efficient across all these possible combinations (dense/sparse, number of channels, batch size)".

Data-partitioning using the Hilbert space filling curves: Effect on the speed of convergence of Fuzzy ARTMAP for large database problems
- Use Hilbert space-filling curves to divide into subproblems for large databases
- Tested on one real-world database (Forest Covertype) and two artificial
- Ran on SCEROLA Beowulf cluster of workstations

Learning to See in the Dark
- CNN for low light images with raw sensor data
- Reduces image processing from traditional pipelines
- New dataset for the paper, 5094 raw exposures
- Trained from scratch using the L1 loss and the Adam optimizer
- Used smartphone images as well

Toward Deeper Understanding of Neural Networks- The Power of Initialization and a Dual View on Expressivity
- Proposed general duality between NN and compositional kernels
- Math background: reproducing kernel Hilbert space (RKHS) or kernel space 
- Extensive explanation of math: taylor series, 
- Using skeletons and compositional kernel spaces, it is possible to understand how functions learn
- State a conjecture that ReLU is more robust to initialization

On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation
- Make a pixel-wise decomposition of nonlinear classifiers
- It helps to visualize the contributions of single pixels to predictions
- Tested on PASCAL VOC 2009, MNIST and pre-trained ImageNet
- Example of Taylor-type and Bag of words decompositions
- An step forward to analytically justify NN results using heatmaps

Explaining NonLinear Classification Decisions with Deep Taylor Decomposition
- Another publication related to previous paper (On Pixel-wise explanations)
- "Deep Taylor Decomposition DNN"
- Use the network structure to back propagate explanations from the output
- MNIST and ILSVRC data sets
- Pixel-wise heatmap explaining why a NN classifier made a particular decision
- Examples of unconstrained (w^2 rule) and constrained (z rules) input spaces
- It is stable under different architectures and datasets, 
- It does not require hyperparameter tuning

Understanding Deep Learning requires rethinking generalization
- This paper tries to expose the idea of NN as just memorizing data sets
- Expose that NN do not distinguish between randomized and real labels
- CIFAR10 and Imagenet as classification benchmarks
- It is mentioned that a 2 layer NN with ReLU activations can represent functions of a certain sample size and dimension
- Exposed a simple experimental framework for defining and understanding a notion of effective capacity of ML models

-------> DCGAN

Generative Adversarial Networks
- First paper about GAN: generator (G) and discriminator (D)
- G tries to fool D improving in the generated output
- Use MNIST, Toronto face database and CIFAR

Improved Techniques for Training GANs
- MNIST, CIFAR-10, ImageNet and SVHN data sets
- Focused on semi-supervised learning, and the generation of images
- The discriminator uses a "minibatch discrimination"
- Improvements on evaluation metrics and unstable training

InfoGAN- Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets
- "InfoGAN learns interpretable representations"
- Tested on MNIST, CelebA, SVHN datasets
- "Completely unsupervised and learns interpretable and disentangled representations on
challenging datasets"

Population Based Training of Neural Networks
- A different approach to tune hyperparameters
- "Improvements in accuracy, training time and stability"
- GAN image generation improves using PBT

Gang of GANs- Generative Adversarial Networks with Maximum Margin Ranking
- Improvements over Wasserstein GAN
- Uses multiple GAN alleviating gradient vanishing, instability and mode collapse
- Tested on visual datasets: CelebA, LSUN Bedroom, CIFAR-10 and 50K-SSFF
- Theoretical background for multiple GAN

DOOM Level Generation using Generative Adversarial Networks
- Use Wasserstein GAN with gradient penalty to create levels in Doom (video game)
- Possible alternative to Procedural Content Generation
- Replaced tanh with sigmoid to suit grey scale colors
- Used Adam optimizer and optimized the discriminator network five times at each update

Wasserstein GAN
- Focused on unsupervised learning defining Earth Mover (EM) distance
- Use WGAN to minimize and approximate EM, which "cures" training problems with GAN
- WGAN train the discriminator to optimality by continuously estimate EM
- According to them, WGAN can improve stability/debugging and remove mode collapse

--------> Languages

A Comparative Study of Programming Languages in Rosetta Code
- Haskell as top 2 for functional language usage in Rosetta.
- Functional and Scripting provide concise code
- Python executables are smaller than Haskell due to static links.
- Haskell smaller run time/memory/error prone than python

Comparative Studies of 10 Programming Languages within 10 Diverse Criteria -- a Team 7 COMP6411-S10 Term Report
- Haskell allows robust, concise, correct software
- Compares Haskell with Java
- 10 criteria for language analysis, among Web apps, secure practices or UI prototyping

Experience Report: Haskell as a Reagent
- Implementation of some Haskell modules into a large scale Python project
- Haskell implementations of an automated computation cluster algorithm
- "Each language has certain characteristics that make it easier and more natural to program in a certain way"
- Functionalize Python later developments after Haskell implementation.
- Compares Haskell partial function application with Python library implementation

An Open-Source Sandbox for Increasing the Accessibility of Functional Programming to the Bioinformatics and Scientific Communities
- Paper backing up the use of functional programming for bioinformatics
- Functional programming languages are better to express math descriptions
- GHCi for interactive environment
- "Haskell code is inherently testable"
- Implementation of a Clojure Amono Acid Predictor

Haskell vs FSharp vs scala- a high-level language features and parallelism support comparison
- Tests performed for Windows and Linux
- The first tests haskell made the best performance in portability
- In parallel performance, haskell demonstrates the best speedups when using more cores
- Laziness as a double edge sword: difficult for HPC but allows infinite structures.

Haskell vs Ada vs Cpp vs Awk vs
- 1994 Research sponsored by DARPA for Naval Surface Warfare Center
- Haskell code took less time to develop and it was more concise/easier to understand
- Haskell lines of code were its minimal, with second in lines of documentation
- Haskell development time was second best (after Relational-Lisp)
- Subjective code evaluation gave an "A" to the haskell prototype

An embedded modeling language approach to interactive 3D and multimedia animation
- 1999 report on how a DSL on top of haskell was used for 3D animations
- First introduction to "Functional Reactive Animations"
- How Haskell enhances: composability, high order functions, strong static typing

------> BNN

How to Train a Compact Binary Neural Network with High Accuracy
- Propose how to train BNN with their own procedures
- Compared with AlexNex, XOR-NN and previous BNN
- Used "PReLU" function for activation
- Used L2 regularization to force weight bipolarization
- High compression rates compared to other BNN implementations

Quantized Neural Networks: Training Neural Networks with Low Precision Weights and Activations
- Trained with  MNIST, CIFAR-10, SVHN and ImageNet datasets
- MNIST QNN 7 times faster than with an unoptimized GPU kernel
- Replaces MAC operations with XNOR and population count
- Same accuracies as typical NN with 4-bit weights and activation Recurrent-QNN
- Implemented NN structures: AlexNet, GoogleNet and ConvNet

Binarized Neural Networks- Training Neural Networks with Weights and Activations Constrained to +1 or −1
- Similar to quantized NN, previous publication
- Extensive explanation of the algorithms used
- Implemented in Theano and Torch (Git repositories)

Embedded Binarized Neural Networks
- Focus BNN for small memory devices (~ KB sizes) like Intel Curie
- Uses just a single floating-point temporary
- Use of "Fused Binary Convolution-Pool Blocks"
- MNIST and CIFAR10 were considered for testing

ReBNet- Residual Binarized Neural Network
- Explains the hardware implementation of a BNN
- Uses "Xnor-Popcount" as a binary dot product
- "Re" stands for reconfigurable
- Explains all phases of a BNN and its advances in parallelization
- Results compared with CIFAR10, SVHN, MNIST, and ILSVRC-2012 (Imagenet)
- ReBNet: scalable bin-CNN that embeds reconfigurability

Recursive Binary Neural Network Learning Model with 2.28b-Weight Storage Requirement
- RBNN that recycle synaptic data during training
- Improvement over BNN for MNIST data set
- This model requires 4x less storage than other binary models
- Storage requirements around 2.28b/synapse

Deep Learning Binary Neural Network on an FPGA
- Explains how to implement a BNN on a FPGA
- It uses only on-chip memory and an efficient batch normalization
- Evaluated using CIFAR-10 with 332,158 img/sec and 86.06% accurracy
- Used Zync ZC706 and Virtex 7 980T

Transfer Learning with Binary Neural Networks
- Have BNN fixed and dynamic sections that are updated later
- Train with Imagenet then perform other tasks or "transfer learning"
- Hybrid HW-SW approach: ship only domain specific NN layers

Build a Compact Binary Neural Network through Bit-level Sensitivity and Data Pruning
- Explores redundant work of BNN to build compact BNN
- Considers sensitivity analysis and bit-level data pruning
- Network size reduced with low accuracy loss, along with less runtime
- Tested on CIFAR-10, SNVH, Chars74K and GTSRB

Fully Parallel RRAM Synaptic Array for Implementing Binary Neural Network
- Considers an parallel array architecture that results in "P-BNN"
- Reduced energy consumption, ~20x improvement over BNN
- Tested for MNIST and ran over TSMC 65nm PDK
- Describes how a "Current Mode Sense Amplifier" can be used
- Uses less circuit area, latency is reduced along with energy consumption

Local Binary Convolutional Neural Networks
- Inspired by Local Binary Patterns, it translates the idea to convolutions
- It shows its mathematical background, with a AlexNet structure
- Tested on MNIST, SVHN, CIFAR-10, and ILSVRC2012 ImageNet

XNOR-Net- ImageNet Classification Using Binary Convolutional Neural Networks
- Two approaches to data quantization
- XNOR-Nets reach 58x convolutional operations that enables CPUs to train the NN
- Tested with ImageNet and ILSVRC2012 using an AlexNet structure
- Reduced network size by around 32X

Bitwise Neural Networks
- Proposed BNN for all elements in the NN
- Tested for MNIST
- Training was done with real values and bitwise 
- Hyperbolic tangent was used for both weight compression and activation

Accelerating Binarized Convolutional Neural Networks with Software-Programmable FPGAs
- BNN on FPGAs with convolutions (Xilinx Zynq-7000 SoC)
- Tested on CIFAR-10
- Implemented in C++
- 35.8 img/sec/watt

Accelerating Binarized Neural Networks- Comparison of FPGA, CPU, GPU, and ASIC
- Test comprehensively between architectures
- FPGA and ASIC have a tight battle
- Network structures: AlexNet, VGG and Neural Talk with CIFAR-10 dataset

FINN- A Framework for Fast, Scalable Binarized Neural Network Inference
- 12.3 million/sec, 0.31 microsec latency and 95.8% accuracy MNIST
- Comprehensive explanation of its FPGA implementation with 90% LUT utilization
- Xilinx Zynq-7000, SoC ZC706

Neural networks with few multiplications
- Test data set: MNIST, CIFAR10, SVHN
- Mayor contribution: Quantized Back Propagation
- Forward pass: binary connect or ternary connect
- Their description tries to eliminate multiplications from all NN stages
- "Ternary connects" is splitting binarization between [-1,0) [0,1]

Towards Accurate Binary Convolutional Neural Network
- Apply convolutions to BNN without prediction degradation, it is called ABC-Net
- This work approximates full-precision weights with linear combination of
multiple binary weight bases
- Employing multiple binary activations to alleviate information loss
- Uses ResNet topology in the ImageNet dataset with close results to full precision nets

Bitwise Neural Networks for Efficient Single-Channel Source Separation
- Use BNN to perform denoising signal operations
- BNNs learn the input Boolean mapping signals and their target Ideal Binary Masks
- Their binarization technique "Quantization-and-Dispersion" encodes magnitude spectra
- A two-stage training strategy was used to prepare a set of compressed weights
- They used their own data set of signals (121080 + 18020 for tests)

Training binary multilayer neural networks for image classification using expectation backpropagation
- Proposed the expected backpropagation based on Bayesian framework
- Tested for the MNIST data set
- Performance is ok but not comparable to other DNN with real values
- Dropout techniques significantly improve BNN with EBP

------> Other

Physics, Topology, Logic and Computation- A Rosetta Stone
- Mentions Category theory from an applied perspective
- Related different branches of science to its application in Category Theory
- Explains concepts in CT like monoidal or CCC
- Mentions lambda calculus in the computation section
- Starts the conversation of how a braided monoidal category can be though of as a quantum process, a tangle or a simple computation.

------> SNN

Bistable Memory and Binary Counters in Spiking Neural Network
- Show how PNGs are capable of retaining triggering events (PNG - Polychronous Group)
- Bistable neural pools can perform tasks such as binary and stack-like counting
- PNGs have the capability of representing data and the power of controlling sequences of actions taking place within the network

Algorithm and Hardware Design of Discrete-Time Spiking Neural Networks Based on Back Propagation with Binary Activations
- Algorithm that uses binary activations with a straight-through gradient estimator
- Implemented on a energy-efficient neuromorphic hardware (28nm CMOS)
- Evaluated for the MNIST dataset (~98% accuracy)
- Cost of 48.4 nJ per classification