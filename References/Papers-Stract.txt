Use Haskell-Clash to develop a CNN for HFT

------> Fin

------> CNN

Applications of Convolutional Neural Networks
- Describe different known applications of CNN
- Computer vision and Natural language processing as their main applications
- Improvements over LSTM RNN, SVN

Recent Advances in Convolutional Neural Networks
- The CNN tree of components, optimizations and applications
- Link to other publications about types of CNN
- General applications in which CNN have been used
- General explanation of how CNN works

Wavelet pooling for convolutional neural networks
- Use wavelet pooling to reduce feature dimensions.
- Uses MatConvNet
- Executed on Intel i7-6800K, 64GB
- MIST, CIFAR, SHVN and KDEF as its applications

Automatic differentiation in machine learning- a survey
- Use automatic diff for gradient decent learning techniques
- Explains what AD is not: numerical diff, symbolic diff.
- Explains how to perform AD and its modes
- How AD and back propagation relate

Deep Convolutional Inverse Graphics Network
- Propose a new architecture for NN using (de)convolutions
- Outputs resistant to rotations, translations or light changes
- Training using "Stochastic Gradient Variational Bayes"
- Image input -> new images with different pose or light
- Applications as well for 3D rendering

Show, Attend and Tell: Neural Image Caption Generation with Visual Attention
- Use convolution and LSTM to extract text information from images
- Flickr8k, Flickr30k and MS COCO datasets with BLEU and METEOR metrics
- MS COCO trained for 3 days using a Titan GPU
- It explains two stochastic attentions: soft and hard

------> CNN-Fin

Intraday prediction of Borsa Istanbul using convolutional neural networks and feature correlations
- Use of CNN to predict stock market price movement using random and naïve   series
- CNN better than Macro Average F-Measure for random and correlated features
- Istanbul stock exchange

Forecasting Stock Prices from the Limit Order Book using Convolutional Neural Networks 
- CNN better than RNN, RBM (Restricted Boltzmann Machine), SVM (Support Vector Machines)
- Taiwan stock exchange

Financial Time-series Data Analysis using Deep Convolutional Neural Networks 
- Transform data into an image
- Executed on a CPU using Matlab

Deep learning for event-driven stock prediction
- Use news as a feature in the CNN
- Comparison of different CNN for market prediction
- NN vs CNN
- Profitability of the CNN against other publications
- S&P stocks

Convolutional Neural Networks Applied to High-Frequency Market Microstructure Forecasting 
- Confirmation of CNN works "reasonably well" on forecasting price trend
- Explains the structure of their CNN for order book and event flow

Multi-Scale Convolutional Neural Networks for Time Series Classification
- Use Multi-Scale CNN for time series classification
- MCNN unifies classification, feature extraction and back propagation
- Comprehensive benchmarking against other TSC algorithms

Conditional Time Series Forecasting with Convolutional Neural Networks
- Use wave CNN to make TSF
- S&P,  Forex and CBOE interest rate as base data
- Comparison against Naïve, LSTM and VAR

Artificial Neural Networks architectures for stock price prediction comparisons and applications
- Implementation of MLP, CNN, LSTM
- Comparison of their performance
- CNN are better than other architectures
- An novel Wavelet-CNN was implemented.

Reading the Tea Leaves- A Neural Network Perspective on Technical Trading
- Use technical analysis for price prediction
- CNN, RNN and many other DNN models tested
- It concludes 'there is no evidence of predictive prowess'

Deep learning for stock market prediction from financial news articles
- Use RCNN compared against other type of CNN
- Use two sources: news and technical indicators
- Prefer sentence embedding rather than word embedding

------> NN-Fin

A Deep Neural-Network Based Stock Trading System Based on Evolutionary Optimized Technical Analysis Parameters 
- Use of NN un a trading system for 30 stocks of the Dow
- Next steps are going to make a CNN 
- Use SMA and RSI 

Adaptive Neuro Fuzzy Inference Systems for High Frequency Financial Trading and Forecasting
- Another Machine learning technique: Adaptive Neuro-Fuzzy Inference System
- Use Sharpe and Sortino ratio
- Comparison against buy and hold
- FOREX for EUR/USD

Using Recurrent Neural Networks To Forecasting of Forex
- Use NN for time series forecasting
- CHF, GBP, Euro and JPN
- Use this as a relation with Bitcoin exchange

Deep learning networks for stock market analysis and prediction - Methodology, data representations, and case studies
- Comprehensive review of current publications
- Use data from the Korean Stock market
- Uses a simple DNN with 3 layers

Adaptive Hybrid Higher Order Neural Networks for Prediction of Stock Market Behavior
- Use Pi-Sigma HONN to make market predictions
- Used for Index and stocks in the USA market
- Used a genetic algorithm and compared that with a gradient decent
- Improved case of GA over GD

Two-Step Disentanglement for Financial Data
- Compare their proposed method with CAPM, Black-Sholes and GAN
- Use their method with MNIST, Sprites NORB, YaleB databases
- Used Nasdaq, NYSE, and AMEX data from 1976-2009
- Beta, rho and mean as benchmarks.
- "our algorithm encodes it as two separate parts, one that keeps the information regarding the labels and the other that is agnostic to the labels"

------> FPGA

Recent Trends in FPGA Architectures and Applications
- Current state for platforms and tools of FPGAs
- Where FPGA are being used: radio astronomy, chip multiprocessor emulation,
particle physics and derivate pricing


Accelerating Large-Scale HPC Applications Using FPGAs
- Use FPGA to accelerate High performance computing
- Comparison with x86
- Modeling wave propagation and credit derivates as its applications

A Pythonic Approach for Rapid Hardware Prototyping and Instrumentation
- Use python as HDL language
- Runs on a Xilinx PynQ Platform
- Also allows simulation within the board


------> FPGA-Fin

Computing system and network architectures in high frequency trading financial applications
- Use Networked FPGAs to obtain sub-microsecond data transfer
- CUDA for HFT algorithm
- Comparison of different CUDA implementations
- x86 vs GPUs

A Hybrid Genetic-Programming Swarm-Optimisation Approach for Examining the Nature and Stability of High Frequency Trading Strategies
- Use genetic algorithms for HFT strategies
- FPGA performs the genetic calculations (15.62x over CPU)
- CPU - FPGA - CPU structure

A Low-Latency Library in FPGA Hardware for High-Frequency Trading (HFT)
- Sustain why low latency is important in HFT transactions
- Whole trading system in the FPGA
- Advantages and disadvantages of a whole system in a FPGA
- "Building and verifying new hardware is more time- consuming than writing new software due to the significantly lower abstraction level in the design flow"
- High throughput 6.1M FIX messages/sec
- FIX as protocol of communication

DSL programmable engine for high frequency trading acceleration
- FPGA vs x86 vs PowerPC
- FAST as protocol of communication
- Directly connected from network to FPGA
- Decreased latency, increased data rate
- DSL for programming via software

FPGA acceleration of quasi-Monte Carlo in finance
- Advantages of using  instead of x86
- Novel publication of quasi-Monte Carlo simulation

High-Performance Quasi-Monte Carlo Financial Simulation: FPGA vs. GPP vs. GPU
- Comparison of FPGA vs other computing architectures
- Financial derivates and QMC simulation
- Throughput and efficiency are compared
- Verilog for FPGA programming
- Speed Up of ~544X vs CPU; 50x vs GPU
- Consumption of 336x CPU, 16x GPU

Low latency book handling in FPGA for high frequency trading
- FPGA implementation of a order book
- Reduced lookup latency
- Large storage due to memory arrangements

Low-Latency FPGA Based Financial Data Feed Handler
- FPGA implementation for data feeds
- FPGA vs CPU
- Almost planar latency when feed rate is increased  on FPGA
- CPU varies linearly positive

Multiplierless Algorithm for Multivariate Gaussian Random Number Generation in FPGAs
- Comparison of FPGA vs CPU vs GPU
- Monte Carlo simulations
- 10x vs GPU, 100X vs CPU


------> CNN-FPGA

A General Neural Network Hardware Architecture on FPGA
- Description of a general NN running on a FPGA
- Base case for CNN, DNN, RNN
- Energy efficient and real time applications

A GPU-Outperforming FPGA Accelerator Architecture for Binary Convolutional Neural Networks
- Implementation of a binary CNN
- Comparison with GPU
- 75x more energy efficient
- 8.3x faster
- Applied to image classification

CirCNN - Accelerating and Compressing Deep Neural Networks Using Block-Circulant Weight Matrices
- Mentions ARM processors along with FPGA chips
- CirCNN implementation
- It is important to reduce CNN complexity to enhance scalability when the model size grows

F-CNN: An FPGA-based framework for training Convolutional Neural Networks
- F-CNN is FPGA-CNN
- Comparison vs CPU and GPU in efficiency and throughput
- Whole implementation, with special focus on training
- Applied for handwritten recognition
- Hybrid design: CPU controller, FPGA accelerator

Why TanH is a Hardware Friendly Activation Function for CNNs
- An alternative activation function for CNN
- Minimum number of circuits required to deploy a CNN
- Comparison of ReLU, Sigmoid and TanH

PipeCNN- An OpenCL-Based Open-Source FPGA Accelerator for Convolution Neural Networks
- Github code at: https://github.com/doonny/PipeCNN
- Full implementation of a CNN on a FPGA
- It uses OpenCL/C++ for code implementation
- It details improvements over other FPGA implementations (2015,2016)
- Implements AlexNet and VGG on a DE5-Net board (Stratix V GXA7)

Minitaur, an Event-Driven FPGA-Based Spiking Network Accelerator
- Used MNIST and 20 newsgroups classification data sets
- Development based on "Spiking" event-driven NN 
- Aims robotics as one of its applications
- Executed on a Xilinx Spartan 6 ZTEX board

------> Haskell

Modeling of dynamic reconfigurable systems with Haskell
- Mathematical description of Run Time Reconfigurable systems
- Use high order functions to generalize rules of abstraction

Roll your own test bed for embedded real-time protocols: a Haskell experience
- Use QuickCheck to generate signals and statistical reliability analysis
- Emulate environments
- Test the physical layer networking

Haskell Ready to Dazzle the Real World
- Desired attributes of Haskell to use as a development language
- Bayesian networks with the Dazzle software program
- GUI interaction between Dazzle and wxHaskell

Financial Software on GPUs- Between Haskell and Fortran
- Haskell vs Fortran
- Describe a generic algorithm for pricing (monte carlo)
- Outline the benefits of FP for functional parallelization

Functional Differentiation of Computer Programs
- Presents an implementation of "Computational Differentiation" (AD synonimn)
- Uses haskell to make that implementation
- Brief introduction to Differential Algebra and its operators
- Applications: Hermite, Lambert functions, WKB expansions, etc

The simple essence of automatic differentiation
- Simplified abstractions about AD
- Use category theory to explain AD with simple terms
- Special emphasis in Forward and Reverse AD for backpropagation
- Theoretical proofs that RAD is more efficient and pararellizable

Compiling To Categories
- Use categorical abstractions to express functions
- With CCC, it is possible to link to Graphs, Circuits or Graphics
- Use Haskell tools to bridge to different platforms
- First approach to declare AD

Beautiful Differentiation
- It explains the details about Automatic Differentiation
- It gives a high level detail of how AD is implemented in haskell
- It generalizes for vector spaces

------> Haskell-FPGA

Haskell as a higher order structural hardware description language
- Published at the same time as "ClasH - From Haskell To Hardware"
- Defend hardware description as a mathematical function application

A mathematical approach towards hardware design 
- Defend that a functional design can be used for logic circuit deployments
- Use clash but also mentions bluespec
- Sustain how basic functions translate to circuits

A fine-grained parallel dataflow-inspired architecture for streaming applications
- Thesis where Haskell and Clash is used
- Description of logic circuits
- Dataflow and coarse-grained reconfigurable arrays used to defend the thesis

A transformation-based approach to hardware design using higher-order functions
- Thesis where Haskell and Clash is used
- Application particule filtering

A two step hardware design method using CλaSH
- A procedure to develop HDL programs with Haskell
- Particle filtering application
- Publication from (previous) thesis 

Comparing CλaSH and VHDL by implementing a dataflow processor
- in some cases, Clash can synthesize better than VHDL code
- Simpler to use a high level language for circuit design
- Application: Dataflow processor
- Less lines of code in clash vs VHDL
- Lower power consumption

ClasH - From Haskell To Hardware
- Master thesis outlining Clash
- Mentions other languages for HDL
- One case study: reduction circuit

Co-simulation between Clash and traditional HDLs
- Use cases for clash when using fpga simulators
- Use verilog procedural interface for the simulation

Specification of apertif polyphase filter bank in Clash
- One formal application of Clash: an apertif polyphase filter bank
- Improvements on performance and clock frequency

System-level modeling of dynamic reconfigurable designs using functional programming abstractions
- Use clash to assign a FPGA section as reconfigurable
- Run embedded linux on the platform


------> DNN

Deep Learning in Neural Networks - An Overview
- A whole survey on how DL has developed until 2014
- Explain origins of DL before 1940
- Special topics in DL: SL, RL, UL.
- References to CNN and its improvements

Deep reinforcement learning - an overview
- "Book" like publication explaining from ground up DNN and RL
- Outline several applications: games, robotics, NLP, Computer Vision, etc
- Provide a plethora of related resources

Wasserstein Learning of Deep Generative Point Process Models
- Use NYSE to train a NN for High frequency transactions
- Several databases with realtime data: MIMIC, Meme, MAS
- Compares its performance against other MLE procedures (¿Maximum Likelihood Estimate?)
- Uses "Temporal point processes" as its main differentiator
- Key words: Wasserstein distance training of RNN point process models

-------> NN

Backwards Differentiation in AD and Neural Nets- Past Links and New Opportunities
- Explains Backwards calculation of derivates or "backpropagation"
- Relates it to Automatic Derivation
- Its application to NN

Pixel Recurrent Neural Networks
- Detail RNN with pixel by pixel spatial dimensions
- Use MNIST, CIFAR, and ImageNet as sources
- Description of a better Diagonal-BiLSTM network.

Auto-Encoding Variational Bayes
- Join a probabilistic model "Variational Bayes" as a gradient learning method
- Deep explanation of the mathematics behind their reasoning
- Uses monte carlo gradient estimator.
- MNIST and Frey Face datasets
- Auto-Encoding VB (AEVB), that learns an approximate inference model using the SGVB estimator

Generative Adversarial Imitation Learning
- New general framework for directly extracting a policy from data
- Describe "Inverse reinforcement learning"
- Uses math to sustain their approach
- This algorithm is evaluated against physics-based control tasks

VIME: Variational Information Maximizing Exploration
- Use "Variational bayes" for Reinforcement Learning
- Backup their statements with mathematical models
- VIME helps training real physical models like: MountainCar, CartPoleSwingup or SwimmerGather
- "VIME is a curiosity-driven exploration strategy for continuous control tasks"

DRAW: A Recurrent Neural Network For Image Generation
- Applied to MNIST, CIFAR, SVHN
- According to authors it is able to generate highly realistic natural images
- "Loss function is a variational upper bound on the log-likelihood of the data"
- Uses two stages: decoding <-> encoding for image generation
- Authors showcase their findings in a youtube video: https://www.youtube.com/watch?v=Zt-7MI9eKEo

Improving Variational Inference with Inverse Autoregressive Flow
- Applied to MNIST, CIFAR
- IAF is a new type of normalizing flow
- Faster sampling in CIFAR thanks to log-likelihood results
- Used variational autoencoders with bidirectional inference 

Equilibrated adaptive learning rates for non-convex
optimization
- An alternative to stochastic gradient decent
- Used MNIST and CURVES datasets
- Experiments ran on a GPU
- It compares its results at par with RMSProp

Generating Sequences With Recurrent Neural Networks
- Use LSTM to generate realistic sequences containing long range structure
- According to authors: "system is able to generate highly realistic cursive
handwriting"
- Can work predicting characters or words
- Used for Penn Treebank and Hutter Prize Wikipedia datasets for text
- IAM Online Handwriting Database for real value data

Recurrent Models of Visual Attention
- Scale image processing considering regions of training
- RNN with back-propagation
- Internal RNN determines which sections should be considered from the whole input
- "Trained end-to-end using a policy gradient method"

Inferring Algorithmic Patterns with Stack-Augmented Recurrent Nets
- Learn how to grow the complexity of a model in a structured way
- Slight improvement using lists or stacks with RNN
- "Complex algorithmic patterns can be more easily learned by composing simpler algorithms"

Reinforcement Learning Neural Turing Machines - Revised
- Outline how a RL-NTM can interact with an input, memory and output "tapes"
- Gradual increments of the problem complexity, as "Curriculum learning"
- Their gradient checking procedure helped to debug any reinforce algorithm
- Used for simple tasks: copy, reverse, duplicate
- Possible future work to implement on a FPGA

Neural Machine Translation by Jointly Learning to Align and Translate
- Extend the classic Encoder - Decoder with a (soft)search-RNN
- It makes translations between english and french
- WMT parallel corpora as a dataset
- It compares its results quantitative and qualitatively

End-To-End Memory Networks
- RNN with (large) external memory
- Train a NN with explicit memory and recurrent attention, 
- A NN with "intuition" of information from a text
- Compared to baseline NN like: LSTM, MemNN and MemNN-WSH (weakly supervised heuristic)

Neural Turing Machines
- Extent the Von Neumann architecture to NN which differentiable end-to-end
- It is able to infer simple algorithms: copy, sort, associative recall.
- NTM interacts with its environment using input - output channels
- NTM uses a controller to read/write from a local memory module

GPU-Accelerated Adjoint Algorithmic Differentiation
- Implementation improvement over naïve AD code
- Feasible for multithreaded environments, specially GPUs
- CPU vs GPU implementations 
- Use vectorization to reduce tape size

Automatic Differentiation of Algorithms for Machine Learning
- Explains AD from basic calculus knowledge
- Links AD with ML algorithms
- Explains Forward and Reverse mode

-------> DCGAN

Generative Adversarial Networks
- First paper about GAN: generator (G) and discriminator (D)
- G tries to fool D improving in the generated output
- Use MNIST, Toronto face database and CIFAR

Improved Techniques for Training GANs
- MNIST, CIFAR-10, ImageNet and SVHN data sets
- Focused on semi-supervised learning, and the generation of images
- The discriminator uses a "minibatch discrimination"
- Improvements on evaluation metrics and unstable training

InfoGAN- Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets
- "InfoGAN learns interpretable representations"
- Tested on MNIST, CelebA, SVHN datasets
- "Completely unsupervised and learns interpretable and disentangled representations on
challenging datasets"

Population Based Training of Neural Networks
- A different approach to tune hyperparameters
- "Improvements in accuracy, training time and stability"
- GAN image generation improves using PBT

--------> Languages

A Comparative Study of Programming Languages in Rosetta Code
- Haskell as top 2 for functional language usage in Rosetta.
- Functional and Scripting provide concise code
- Python executables are smaller than Haskell due to static links.
- Haskell smaller run time/memory/error prone than python

Comparative Studies of 10 Programming Languages within 10 Diverse Criteria -- a Team 7 COMP6411-S10 Term Report
- Haskell allows robust, concise, correct software
- Compares Haskell with Java
- 10 criteria for language analysis, among Web apps, secure practices or UI prototyping

Experience Report: Haskell as a Reagent
- Implementation of some Haskell modules into a large scale Python project
- Haskell implementations of an automated computation cluster algorithm
- "Each language has certain characteristics that make it easier and more natural to program in a certain way"
- Functionalize Python later developments after Haskell implementation.
- Compares Haskell partial function application with Python library implementation

An Open-Source Sandbox for Increasing the Accessibility of Functional Programming to the Bioinformatics and Scientific Communities
- Paper backing up the use of functional programming for bioinformatics
- Functional programming languages are better to express math descriptions
- GHCi for interactive environment
- "Haskell code is inherently testable"
- Implementation of a Clojure Amono Acid Predictor

Haskell vs FSharp vs scala- a high-level language features and parallelism support comparison
- Tests performed for Windows and Linux
- The first tests haskell made the best performance in portability
- In parallel performance, haskell demonstrates the best speedups when using more cores
- Laziness as a double edge sword: difficult for HPC but allows infinite structures.

Haskell vs Ada vs Cpp vs Awk vs
- 1994 Research sponsored by DARPA for Naval Surface Warfare Center
- Haskell code took less time to develop and it was more concise/easier to understand
- Haskell lines of code were its minimal, with second in lines of documentation
- Haskell development time was second best (after Relational-Lisp)
- Subjective code evaluation gave an "A" to the haskell prototype

An embedded modeling language approach to interactive 3D and multimedia animation
- 1999 report on how a DSL on top of haskell was used for 3D animations
- First introduction to "Functional Reactive Animations"
- How Haskell enhances: composability, high order functions, strong static typing
