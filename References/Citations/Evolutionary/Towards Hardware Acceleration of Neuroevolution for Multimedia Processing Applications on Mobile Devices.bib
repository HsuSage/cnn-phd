@InProceedings{10.1007/11893295_130,
author="Larkin, Daniel
and Kinane, Andrew
and O'Connor, Noel",
editor="King, Irwin
and Wang, Jun
and Chan, Lai-Wan
and Wang, DeLiang",
title="Towards Hardware Acceleration of Neuroevolution for Multimedia Processing Applications on Mobile Devices",
booktitle="Neural Information Processing",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="1178--1188",
abstract="This paper addresses the problem of accelerating large artificial neural networks (ANN), whose topology and weights can evolve via the use of a genetic algorithm. The proposed digital hardware architecture is capable of processing any evolved network topology, whilst at the same time providing a good trade off between throughput, area and power consumption. The latter is vital for a longer battery life on mobile devices. The architecture uses multiple parallel arithmetic units in each processing element (PE). Memory partitioning and data caching are used to minimise the effects of PE pipeline stalling. A first order minimax polynomial approximation scheme, tuned via a genetic algorithm, is used for the activation function generator. Efficient arithmetic circuitry, which leverages modified Booth recoding, column compressors and carry save adders, is adopted throughout the design.",
isbn="978-3-540-46485-3"
}

