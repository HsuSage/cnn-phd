@article {Esser11441,
	author = {Esser, Steven K. and Merolla, Paul A. and Arthur, John V. and Cassidy, Andrew S. and Appuswamy, Rathinakumar and Andreopoulos, Alexander and Berg, David J. and McKinstry, Jeffrey L. and Melano, Timothy and Barch, Davis R. and di Nolfo, Carmelo and Datta, Pallab and Amir, Arnon and Taba, Brian and Flickner, Myron D. and Modha, Dharmendra S.},
	title = {Convolutional networks for fast, energy-efficient neuromorphic computing},
	volume = {113},
	number = {41},
	pages = {11441--11446},
	year = {2016},
	doi = {10.1073/pnas.1604850113},
	publisher = {National Academy of Sciences},
	abstract = {Brain-inspired computing seeks to develop new technologies that solve real-world problems while remaining grounded in the physical requirements of energy, speed, and size. Meeting these challenges requires high-performing algorithms that are capable of running on efficient hardware. Here, we adapt deep convolutional neural networks, which are today{\textquoteright}s state-of-the-art approach for machine perception in many domains, to perform classification tasks on neuromorphic hardware, which is today{\textquoteright}s most efficient platform for running neural networks. Using our approach, we demonstrate near state-of-the-art accuracy on eight datasets, while running at between 1,200 and 2,600 frames/s and using between 25 and 275 mW.Deep networks are now able to achieve human-level performance on a broad spectrum of recognition tasks. Independently, neuromorphic computing has now demonstrated unprecedented energy-efficiency through a new chip architecture based on spiking neurons, low precision synapses, and a scalable communication network. Here, we demonstrate that neuromorphic computing, despite its novel architectural primitives, can implement deep convolution networks that (i) approach state-of-the-art classification accuracy across eight standard datasets encompassing vision and speech, (ii) perform inference while preserving the hardware{\textquoteright}s underlying energy-efficiency and high throughput, running on the aforementioned datasets at between 1,200 and 2,600 frames/s and using between 25 and 275 mW (effectively \&gt;6,000 frames/s per Watt), and (iii) can be specified and trained using backpropagation with the same ease-of-use as contemporary deep learning. This approach allows the algorithmic power of deep learning to be merged with the efficiency of neuromorphic processors, bringing the promise of embedded, intelligent, brain-inspired computing one step closer.},
	issn = {0027-8424},
	URL = {https://www.pnas.org/content/113/41/11441},
	eprint = {https://www.pnas.org/content/113/41/11441.full.pdf},
	journal = {Proceedings of the National Academy of Sciences}
}
