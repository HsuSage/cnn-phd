@INPROCEEDINGS{8052915,
author={Y. Zhou and S. Redkar and X. Huang},
booktitle={2017 IEEE 60th International Midwest Symposium on Circuits and Systems (MWSCAS)},
title={Deep learning binary neural network on an FPGA},
year={2017},
pages={281-284},
abstract={As a popular deep learning technique, convolutional neural network has been widely used in many tasks such as image classification and object recognition. Convolutional neural network exploits spatial correlations in the images by performing convolution operations in local receptive fields. Convolutional neural networks are preferred over fully connected neural networks because they have fewer weights and are easier to train. Many research works have been conducted to reduce the computational complexity and memory requirements of convolutional neural network, to make it applicable to the low-power embedded applications with limited memories. This paper presents the architecture design of convolutional neural network with binary weights and activations, also known as binary neural network, on an FPGA platform. Weights and input activations are binarized with only two values, +1 and -1. This reduces all the fixed point multiplication operations in convolutional layers and fully connected layers to 1-bit XNOR operations. The proposed design uses only on-chip memories. Furthermore, an efficient implementation of batch normalization operation is introduced. When evaluating the CIFAR-10 benchmark, the proposed FPGA design can achieve a processing rate of 332,158 images per second with with accuracy of 86.06% using 1-bit quantized weights and activations.},
keywords={field programmable gate arrays;fixed point arithmetic;image classification;learning (artificial intelligence);neural nets;object recognition;quantisation (signal);1-bit XNOR operation;CIFAR-10 benchmark;FPGA platform;batch normalization operation;computational complexity reduction;convolutional neural network;deep learning binary neural network;fixed point multiplication operation;local receptive fields;low-power embedded applications;memory requirement reduction;on-chip memories;spatial correlation;Biological neural networks;Convolution;Field programmable gate arrays;Hardware;Memory management;Training},
doi={10.1109/MWSCAS.2017.8052915},
ISSN={},
month={Aug},}