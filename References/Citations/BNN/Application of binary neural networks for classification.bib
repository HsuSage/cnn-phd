@INPROCEEDINGS{1259700,  author={Yi Xu and N. S. Chaudhari}, booktitle={Proceedings of the 2003 International Conference on Machine Learning and Cybernetics (IEEE Cat. No.03EX693)},  title={Application of binary neural networks for classification},  year={2003}, volume={3}, number={}, pages={1343-1348 Vol.3}, abstract={Learning problem for neural networks has widely been investigated in last two decades. Kim and Park [J.H. Kim et al., Jan. 1995] proposed one approach based on geometric technique, called "expand and truncate learning (ETL)". ETL is proposed to construct a three-layer binary neural network (BNN) for training a Boolean function of n (Boolean) variables. It is claimed by Kim and Park in [J.H. Kim et al., Jan. 1995] that, neural networks constructed according to this technique are much smaller. This paper investigates usefulness of these ideas for data classification. Data classification in real world involves multiple classes. For solving this problem, there are many techniques based on statistical principles, clustering approaches, etc. Application of binary neural networks for multiple outputs are important in practice. We propose a method for construction of a binary neural net based on generalization of ETL to more than two classes. Our method simplifies the resulting neural network architecture.}, keywords={neural nets;pattern classification;learning (artificial intelligence);Boolean functions;binary neural networks;geometric technique;expand and truncate learning;Boolean function;data classification;core vertex;neural network training;Neural networks;Neurons;Artificial neural networks;Power line communications;Machine learning algorithms;Application software;Boolean functions;Pattern classification;Function approximation;Pattern matching}, doi={10.1109/ICMLC.2003.1259700}, ISSN={}, month={Nov},}
