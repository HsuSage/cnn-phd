NN 

Backwards Differentiation in AD and Neural Nets- Past Links and New Opportunities
https://link.springer.com/chapter/10.1007/3-540-28438-9_2
http://www.werbos.com/AD2004.pdf

Pixel Recurrent Neural Networks
https://arxiv.org/abs/1601.06759

Auto-Encoding Variational Bayes
https://arxiv.org/abs/1312.6114

Generative Adversarial Imitation Learning
https://arxiv.org/abs/1606.03476

VIME: Variational Information Maximizing Exploration
https://arxiv.org/abs/1605.09674

DRAW: A Recurrent Neural Network For Image Generation
https://arxiv.org/abs/1502.04623

Improving Variational Inference with Inverse Autoregressive Flow
https://arxiv.org/abs/1606.04934

Equilibrated adaptive learning rates for non-convex
optimization
https://arxiv.org/abs/1502.04390

Generating Sequences With Recurrent Neural Networks
https://arxiv.org/abs/1308.0850

Recurrent Models of Visual Attention
https://arxiv.org/abs/1406.6247

Inferring Algorithmic Patterns with Stack-Augmented Recurrent Nets
https://arxiv.org/abs/1503.01007

Reinforcement Learning Neural Turing Machines - Revised
https://arxiv.org/abs/1505.00521

Neural Machine Translation by Jointly Learning to Align and Translate
https://arxiv.org/abs/1409.0473

End-To-End Memory Networks
https://arxiv.org/abs/1503.08895

Neural Turing Machines
https://arxiv.org/abs/1410.5401

A Survey of Neuromorphic Computing and Neural Networks in Hardware
https://arxiv.org/abs/1705.06963

GPU-Accelerated Adjoint Algorithmic Differentiation
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4772124/

Automatic Differentiation of Algorithms for Machine Learning
https://arxiv.org/abs/1404.7456

Online learning rate adaptation with hypergradient descent
https://openreview.net/forum?id=BkrsAzWAb

Discrete first- and second-order adjoints and automatic differentiation for the sensitivity analysis of dynamic models
https://www.researchgate.net/publication/220307980_Discrete_first-_and_second-order_adjoints_and_automatic_differentiation_for_the_sensitivity_analysis_of_dynamic_models

Neural Network Design for J Function Approximation in Dynamic Programming
https://arxiv.org/abs/adap-org/9806001

Delving Deep into Rectifiers- Surpassing Human-Level Performance on ImageNet Classification
https://arxiv.org/abs/1502.01852

Development and Implementation of Parameterized FPGA-Based General Purpose Neural Networks for Online Applications
https://ieeexplore-ieee-org.ezproxy.auckland.ac.nz/abstract/document/5607329/

Artificial Neural Network Implementation on a single FPGA of a Pipelined On- Line Backpropagation
https://dl-acm-org.ezproxy.auckland.ac.nz/citation.cfm?id=501837

Adam: a method for stochastic optimization
https://arxiv.org/abs/1412.6980

NetAdapt- Platform-Aware Neural Network Adaptation for Mobile Applications
https://arxiv.org/abs/1804.03230
http://eyeriss.mit.edu/

Hardware for Machine Learning- Challenges and Opportunities
https://arxiv.org/abs/1612.07625

Efficient Processing of Deep Neural Networks- A Tutorial and Survey
https://arxiv.org/abs/1703.09039

Understanding the Limitations of Existing Energy-Efficient Design Approaches for Deep Neural Networks
https://www.semanticscholar.org/paper/Understanding-the-Limitations-of-Existing-Design-Chen-Yang/3a7509a72a01dae5e17f1405ab3d18e1e2fd8157
http://www.rle.mit.edu/eems/publications/

Data-partitioning using the Hilbert space filling curves: Effect on the speed of convergence of Fuzzy ARTMAP for large database problems
https://www-sciencedirect-com.ezproxy.auckland.ac.nz/science/article/pii/S089360800500047X

Toward Deeper Understanding of Neural Networks- The Power of Initialization and a Dual View on Expressivity
https://arxiv.org/abs/1602.05897

Functional data learning by Hilbert feedforward neural networks
https://onlinelibrary-wiley-com.ezproxy.auckland.ac.nz/action/showCitFormats?doi=10.1002%2Fmma.2641

On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation
http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0130140

Explaining NonLinear Classification Decisions with Deep Taylor Decomposition
https://arxiv.org/abs/1512.02479

Understanding Deep Learning requires rethinking generalization
https://arxiv.org/abs/1611.03530

Improving back-propagation by adding an adversarial gradient
https://arxiv.org/abs/1510.04189

Neuroscience-Inspired Artificial Intelligence
https://www-sciencedirect-com.ezproxy.auckland.ac.nz/science/article/pii/S0896627317305093

Overcoming catastrophic forgetting in neural networks
https://arxiv.org/abs/1612.00796

Training and inference with integers in deep neural networks
https://arxiv.org/abs/1802.04680

Dorefa-net- training low bitwidth convolutional neural networks with low bitwidth gradients
https://arxiv.org/abs/1606.06160
